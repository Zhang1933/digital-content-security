# 数字内容安全小学期实践

### 进入所在目录
用pipenv 管理环境 初始pipenv,换源已经弄好了
```python
# 安装环境
pipenv install
# 进入虚拟环境：
pipenv shell
```

## web 部分
支持点赞.
用户登陆可管理自己上传的图片,添加、删除。
用户登出可看到所有用户上传的图片,点赞
用户登陆之后获得用户公钥，来让后面的uploader_helper 客户端与服务器之间保密通信。

## 水印嵌入部分
### 水印算法：LSB替换算法
算法原理：对载体图像的每个像素，都对其RGB三通道的LSB嵌入秘密信息
### 帮助文档：
#### getFilelist(flst=os.path.expanduser('~'))
函数功能：遍历根目录下的所有子目录，以列表的形式返回所有的不含中文字符的子文件夹名称，默认根目录为用户目录
输入：（可选）要遍历的根目录名称
输出：含有所有子文件夹名称的列表
#### embed(filelist，imgpath)
函数功能：水印嵌入算法
imgpath:载体图像的相对或绝对路径
filelist:作为秘密信息的二进制比特流
函数结果：在当前文件夹下生成含密图像'ushimaru_LSB.png'
#### imagecapacity(imgpath)
函数功能：测量待检测图像的容量
输入：待测图片的路径名
输出：图片的可嵌入秘密信息的三通道LSB数量，int
#### extract(imgpath,begin,length)
函数功能：水印提取算法，提取载体图像中的原始秘密信息二进制比特流
imgpath:含密图像的路径
begin:在载体图像的第几个LSB开始提取信息
length：比特流秘密信息的长度
输出：以字符串形式返回秘密信息的二进制比特流
## 爬虫部分

### 爬虫原理 
利用正则表达式判断目标网站中所有的图片信息，并将其链接在列表里保存下来。遍历整个网站后，依次访问链接所对应的图片并将它们保存下来

### 帮助文档
库名re_crawler

函数名：crwaler

函数所需传入变量：url,path

所要传入的第一个变量url为所需爬取的网站的地址（包括端口号），**以字符串形式输入**。形如 xxx.xxx.xxx.xxx:yyyy。库为这一变量设置了默认值：192.168.43.137:5000。

所要传入的第二个变量path为爬取图片的保存文件夹。**以字符串形式输入**需要使用者输入理想的保存文件夹的路径。库不会自行创建一个新的文件夹，只能将图片保存在一个已有的文件夹里。库为这个变量设置了一个默认值：image\\\

保存的文件命名用下划线‘\_’分隔。以 “num\_?.xxx”形式保存图片。num表示图片顺序，？所代表数字与原图在网站中标识相关，xxx为图片格式
## 客户端批量上传 upload_helper.py
进入client 子目录
```
pipenv install 
```
```
pipenv shell 
```
进入虚拟环境之后,输入
```
python upload_helper.py -h
```
查看帮助信息，根据帮助信息输入参数运行。运行后，会自动读取用户目录下的文件列表作为信息嵌入。若所要嵌入的信息过大，那么程序会将本次读取到的尽量多的信息分片嵌入在本次添加的路径中的不同图片中。
## 爬取信息，得到隐私信息
进入crawler子目录
进入pipenv虚拟环境，运行：
```
python get_message.py
```
输入crawl url,之后爬取的图片自动保存在img子目录,然后会程序会提取所嵌入的信息,并将分片的信息重新组合写入在当前一个data.txt文件下。
